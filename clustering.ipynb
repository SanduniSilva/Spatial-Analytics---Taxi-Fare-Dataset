{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "dataset_path = \"D:/Uni/6 Semester/Spatial Analytics/Assignments/ML/train.csv\"\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                     key  fare_amount          pickup_datetime  \\\n",
      "0           2009-06-15 17:26:21.0000001          4.5  2009-06-15 17:26:21 UTC   \n",
      "1           2010-01-05 16:52:16.0000002         16.9  2010-01-05 16:52:16 UTC   \n",
      "2          2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n",
      "3           2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n",
      "4         2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n",
      "...                                 ...          ...                      ...   \n",
      "55423851   2014-03-15 03:28:00.00000070         14.0  2014-03-15 03:28:00 UTC   \n",
      "55423852    2009-03-24 20:46:20.0000002          4.2  2009-03-24 20:46:20 UTC   \n",
      "55423853    2011-04-02 22:04:24.0000004         14.1  2011-04-02 22:04:24 UTC   \n",
      "55423854    2011-10-26 05:57:51.0000002         28.9  2011-10-26 05:57:51 UTC   \n",
      "55423855   2014-12-12 11:33:00.00000015          7.5  2014-12-12 11:33:00 UTC   \n",
      "\n",
      "          pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "0               -73.844311        40.721319         -73.841610   \n",
      "1               -74.016048        40.711303         -73.979268   \n",
      "2               -73.982738        40.761270         -73.991242   \n",
      "3               -73.987130        40.733143         -73.991567   \n",
      "4               -73.968095        40.768008         -73.956655   \n",
      "...                    ...              ...                ...   \n",
      "55423851        -74.005272        40.740027         -73.963280   \n",
      "55423852        -73.957784        40.765530         -73.951640   \n",
      "55423853        -73.970505        40.752325         -73.960537   \n",
      "55423854        -73.980901        40.764629         -73.870605   \n",
      "55423855        -73.969722        40.797668         -73.970885   \n",
      "\n",
      "          dropoff_latitude  passenger_count  \n",
      "0                40.712278                1  \n",
      "1                40.782004                1  \n",
      "2                40.750562                2  \n",
      "3                40.758092                1  \n",
      "4                40.783762                1  \n",
      "...                    ...              ...  \n",
      "55423851         40.762555                1  \n",
      "55423852         40.773959                1  \n",
      "55423853         40.797342                1  \n",
      "55423854         40.773963                1  \n",
      "55423855         40.783313                1  \n",
      "\n",
      "[55423856 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 55423856\n",
      "New size: 55423480\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "print('Old size: %d' % len(df))\n",
    "df = df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing numerical values\n",
    "scaler = StandardScaler()\n",
    "df[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']] = scaler.fit_transform(df[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# OPTICS clustering\u001b[39;00m\n\u001b[0;32m      5\u001b[0m optics \u001b[38;5;241m=\u001b[39m OPTICS(min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, xi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, min_cluster_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optics\u001b[38;5;241m.\u001b[39mfit_predict(\u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# saving the dataframe\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OPTICS clustering\n",
    "optics = OPTICS(min_samples=5, xi=0.05, min_cluster_size=0.05)\n",
    "df['pickup_cluster'] = optics.fit_predict(df[['pickup_longitude', 'pickup_latitude']])\n",
    "\n",
    "# saving the dataframe\n",
    "df.to_csv('new_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
